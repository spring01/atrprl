
import os
os.environ['OMP_NUM_THREADS'] = '1'
import numpy as np
import gym
from gym.envs.registration import register
from hcdrl.common.envwrapper import HistoryStacker


var49 = [4.27536053e-09,   7.77258204e-08,   7.07354785e-07,   4.29710393e-06,
         1.96061979e-05,   7.16791785e-05,   2.18774431e-04,   5.73528863e-04,
         1.31877652e-03,   2.70314739e-03,   5.00358248e-03,   8.45409966e-03,
         1.31585405e-02,   1.90194988e-02,   2.57160462e-02,   3.27464174e-02,
         3.95257673e-02,   4.55066954e-02,   5.02825516e-02,   5.36432582e-02,
         5.55741421e-02,   5.62093233e-02,   5.57636812e-02,   5.44682304e-02,
         5.25255911e-02,   5.00908060e-02,   4.72732726e-02,   4.41507601e-02,
         4.07863363e-02,   3.72418123e-02,   3.35849217e-02,   2.98903844e-02,
         2.62366412e-02,   2.27004732e-02,   1.93513867e-02,   1.62469987e-02,
         1.34300303e-02,   1.09270389e-02,   8.74872377e-03,   6.89148447e-03,
         5.33984777e-03,   4.06937463e-03,   3.04969310e-03,   2.24736323e-03,
         1.62835760e-03,   1.16002575e-03,   8.12492583e-04,   5.59509805e-04,
         3.78830007e-04,   2.52202729e-04,   1.65101897e-04,   1.06288526e-04,
         6.72967705e-05,   4.19104882e-05,   2.56758016e-05,   1.54758542e-05,
         9.17856825e-06,   5.35733259e-06,   3.07781208e-06,   1.74070120e-06,
         9.69316792e-07,   5.31543614e-07,   2.87089433e-07,   1.52747808e-07,
         8.00731982e-08,   4.13646188e-08,   2.10608503e-08,   1.05706832e-08,
         5.23100898e-09,   2.55268764e-09,   1.22860891e-09,   5.83319787e-10,
         2.73243180e-10,   1.26302856e-10,   5.76194279e-11,   2.59469528e-11,
         1.15354387e-11,   5.06383816e-12,   2.19528031e-12,   9.40004657e-13,
         3.97616274e-13,   1.66171120e-13,   6.86224430e-14,   2.80063738e-14,
         1.12976307e-14,   4.50522248e-15,   1.77623716e-15,   6.92465077e-16,
         2.66969897e-16,   1.01800152e-16,   3.83980731e-17,   1.43283916e-17,
         5.29009634e-18,   1.93267118e-18,   6.98762790e-19,   2.50050185e-19,
         8.85722096e-20,   3.10589686e-20,   1.07830424e-20,   3.70684935e-21,]
register(
    id='ATRP-ps-td-test-v0',
    entry_point='atrp:ATRPTargetDistrib',
    max_episode_steps=100000,
    kwargs={
        'max_rad_len': 100,
        'step_time': 1e2,
        'completion_time': 1e5,
        'min_steps': 100,
        'termination': False,
        'k_prop': 1.6e3,
        'k_act': 0.45,
        'k_deact': 1.1e7,
        'k_ter': 1e8,
        'observation_mode': 'all stable',
        'mono_init': 0.0,
        'cu1_init': 0.0,
        'cu2_init': 0.0,
        'dorm1_init': 0.0,
        'mono_unit': 0.1,
        'cu1_unit': 0.004,
        'cu2_unit': 0.004,
        'dorm1_unit': 0.008,
        'mono_cap': 10.0,
        'cu1_cap': 0.2,
        'cu2_cap': 0.2,
        'dorm1_cap': 0.4,
        'mono_density': 8.73,
        'sol_init': 0.01,
        'sol_cap': 0.0,
        'reward_chain_type': 'dorm',
        'dn_distribution': var49,
        'ks_num_sample': 2e3,
    }
)


env = gym.make('ATRP-ps-td-test-v0')
env = HistoryStacker(env, num_frames=1, act_steps=4)

for _ in range(100):
    state = env.reset()
    for i in range(3000):
        action = np.random.randint(6)
        state, reward, done, info = env.step(action)
        if done:
            break
    print(reward)
    env.render()
